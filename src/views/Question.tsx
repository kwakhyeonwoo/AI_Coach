import React, { useEffect, useRef, useState } from 'react';
import { View, Text, StyleSheet, Pressable, ActivityIndicator, Alert, Animated, Easing, Linking } from 'react-native';
import { MaterialCommunityIcons } from '@expo/vector-icons';
import type { NativeStackScreenProps } from '@react-navigation/native-stack';
import type { RootStackParamList, QA } from '../models/types';
import { useInterviewVM } from '../viewmodels/InterviewVM';
import { requestFirstQuestion, requestNextQuestion } from '../services/apiClient';

// âœ… expo-audio ì‚¬ìš©
import {
  useAudioRecorder,
  RecordingPresets,
  setAudioModeAsync,
  requestRecordingPermissionsAsync,
  getRecordingPermissionsAsync,
} from 'expo-audio';

import AsyncStorage from '@react-native-async-storage/async-storage';

type Props = NativeStackScreenProps<RootStackParamList, 'Question'>;

// âœ… ìµœì´ˆ 1íšŒ ì•ˆë‚´ Alert í”Œë˜ê·¸ í‚¤
const MIC_PREASK_KEY = 'mic_preask_done_v1';

const SmallBtn: React.FC<{ label: string; onPress?: () => void; disabled?: boolean }>
  = ({ label, onPress, disabled }) => (
    <Pressable onPress={onPress} disabled={disabled}
      style={({ pressed }) => [styles.smallBtn, pressed && { opacity: 0.7 }, disabled && { opacity: 0.4 }]}
    >
      <Text style={styles.smallBtnText}>{label}</Text>
    </Pressable>
  );

const Question: React.FC<Props> = ({ route, navigation }) => {
  const { settings } = useInterviewVM();
  const maxQ = 5;
  const [index, setIndex] = useState(1);
  const [loading, setLoading] = useState(false);
  const [question, setQuestion] = useState<string>('');
  const [history, setHistory] = useState<QA[]>([]);
  const [followups, setFollowups] = useState(0);

  // ğŸ”Š ìƒíƒœ
  const [isRecording, setIsRecording] = useState(false);
  const [remain, setRemain] = useState(90);
  const [audioUri, setAudioUri] = useState<string | undefined>();
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // íŒŒë™/í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜
  const [level, setLevel] = useState(0);                 // 0~1
  const pulse = useRef(new Animated.Value(0)).current;   // ì™¸ê³½ ë§ í„ìŠ¤

  useEffect(() => {
    if (isRecording) {
      const loop = Animated.loop(
        Animated.sequence([
          Animated.timing(pulse, { toValue: 1, duration: 600, easing: Easing.out(Easing.quad), useNativeDriver: true }),
          Animated.timing(pulse, { toValue: 0, duration: 600, easing: Easing.in(Easing.quad), useNativeDriver: true }),
        ]),
      );
      loop.start();
      return () => loop.stop();
    } else {
      pulse.stopAnimation();
      pulse.setValue(0);
      setLevel(0);
    }
  }, [isRecording]);

  // ì²« ì§ˆë¬¸ ë¡œë“œ
  useEffect(() => {
    (async () => {
      setLoading(true);
      try {
        const res = await requestFirstQuestion(settings, { maxQ: 5 });
        if (res.question) setQuestion(res.question);
      } catch (e: any) {
        Alert.alert('ì§ˆë¬¸ ë¡œë“œ ì‹¤íŒ¨', e?.message ?? 'ì„œë²„ ì˜¤ë¥˜');
      } finally {
        setLoading(false);
      }
    })();

    // ì–¸ë§ˆìš´íŠ¸ ì‹œ ë…¹ìŒ/íƒ€ì´ë¨¸ ì •ë¦¬
    return () => { stopRecording().catch(()=>{}); };
  }, []);

  type MeteringStatus = { metering?: number | null };

  // âœ… expo-audio ë…¹ìŒê¸° + ë©”í„°ë§
  const recorder = useAudioRecorder(
    { ...RecordingPresets.HIGH_QUALITY, isMeteringEnabled: true },
    (st: unknown) => {
      const m = (st as MeteringStatus)?.metering;
      if (typeof m === 'number') {
        const norm = Math.min(1, Math.max(0, (m + 160) / 160));
        setLevel(prev => prev * 0.6 + norm * 0.4);
      } else {
        // (Android ë“±) ë©”í„°ë§ ë¯¸ì§€ì› ì‹œ ì˜ì‚¬ íŒŒí˜•
        setLevel(prev => prev * 0.75 + 0.25 * (0.3 + Math.random() * 0.7));
      }
    }
  );

  // â¯ ë§ˆì´í¬ ë²„íŠ¼: ìµœì´ˆ 1íšŒë§Œ ìš°ë¦¬ Alert â†’ ê·¸ ë‹¤ìŒë¶€í„´ ë°”ë¡œ ë™ì‘
  const handleMicPress = async () => {
    try {
      const perm = await getRecordingPermissionsAsync();
      const shown = await AsyncStorage.getItem(MIC_PREASK_KEY);

      // âœ… 1) ìš°ë¦¬ ì•ˆë‚´ Alertë¥¼ 'ë¬´ì¡°ê±´' ë”± í•œ ë²ˆ ë¨¼ì € ë³´ì—¬ì¤€ë‹¤ (ê¶Œí•œ ìƒíƒœì™€ ë¬´ê´€)
      if (!shown) {
        await AsyncStorage.setItem(MIC_PREASK_KEY, '1'); // ë‹¤ì‹œëŠ” ì•ˆ ë³´ì´ê²Œ

        if (perm.granted) {
          // ì´ë¯¸ OS ê¶Œí•œì´ ìˆëŠ” ê²½ìš°: ì•ˆë‚´ í›„ ë°”ë¡œ ë…¹ìŒ ì‹œì‘ ì„ íƒ
          Alert.alert(
            'ë§ˆì´í¬ ì‚¬ìš© ì•ˆë‚´',
            'ì§€ê¸ˆë¶€í„° ë§ˆì´í¬ ë…¹ìŒì„ ì‹œì‘í• ê²Œìš”.',
            [
              { text: 'ì·¨ì†Œ', style: 'cancel' },
              { text: 'ì‹œì‘', onPress: () => startRecording() },
            ],
          );
          return;
        }

        if (perm.status === 'undetermined') {
          // ì•„ì§ í•œ ë²ˆë„ OS ê¶Œí•œì„ ì•ˆ ë¬¼ì–´ë³¸ ê²½ìš°: ì•ˆë‚´ â†’ OS ë‹¤ì´ì–¼ë¡œê·¸
          Alert.alert(
            'ë§ˆì´í¬ ì‚¬ìš© ì•ˆë‚´',
            'ë‹¤ìŒ ë‹¨ê³„ì—ì„œ OS ê¶Œí•œì„ ìš”ì²­í•©ë‹ˆë‹¤.',
            [
              { text: 'ì·¨ì†Œ', style: 'cancel' },
              {
                text: 'ë™ì˜í•˜ê³  ê³„ì†',
                onPress: async () => {
                  const req = await requestRecordingPermissionsAsync();
                  if (req.granted) await startRecording();
                  else Alert.alert('ë§ˆì´í¬ ê¶Œí•œ í•„ìš”', 'ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
                },
              },
            ],
          );
          return;
        }

        // ëª…ì‹œì ìœ¼ë¡œ ê±°ë¶€ë¼ ìˆëŠ” ê²½ìš°
        Alert.alert(
          'ë§ˆì´í¬ ê¶Œí•œì´ êº¼ì ¸ ìˆì–´ìš”',
          'ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ë©´ ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
          [
            { text: 'ì·¨ì†Œ', style: 'cancel' },
            { text: 'ì„¤ì • ì—´ê¸°', onPress: () => Linking.openSettings?.() },
          ],
        );
        return;
      }

      // âœ… 2) ì´ë¯¸ í•œ ë²ˆ ì•ˆë‚´ë¥¼ ë³´ì—¬ì¤¬ë‹¤ë©´, ê¶Œí•œ ìƒíƒœì— ë”°ë¼ ë°”ë¡œ ë™ì‘
      if (perm.granted) {
        if (isRecording) await stopRecording();
        else await startRecording();
        return;
      }

      if (perm.status === 'undetermined') {
        const req = await requestRecordingPermissionsAsync();
        if (req.granted) await startRecording();
        else Alert.alert('ë§ˆì´í¬ ê¶Œí•œ í•„ìš”', 'ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        return;
      }

      Alert.alert(
        'ë§ˆì´í¬ ê¶Œí•œì´ êº¼ì ¸ ìˆì–´ìš”',
        'ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ë©´ ë…¹ìŒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
        [
          { text: 'ì·¨ì†Œ', style: 'cancel' },
          { text: 'ì„¤ì • ì—´ê¸°', onPress: () => Linking.openSettings?.() },
        ],
      );
    } catch (e) {
      console.warn('handleMicPress error', e);
    }
  };



  const startRecording = async () => {
    try {
      await setAudioModeAsync({
        playsInSilentMode: true,
        allowsRecording: true,
      });

      await recorder.prepareToRecordAsync();
      recorder.record();

      setIsRecording(true);
      setAudioUri(undefined);
      setRemain(90);

      // âœ… 90ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´
      if (timerRef.current) clearInterval(timerRef.current);
      timerRef.current = setInterval(() => {
        setRemain((r) => {
          if (r <= 1) {
            clearInterval(timerRef.current!);
            timerRef.current = null;
            // ìë™ ì¢…ë£Œ
            stopRecording().catch(()=>{});
            return 0;
          }
          return r - 1;
        });
      }, 1000);
    } catch (e: any) {
      console.warn('startRecording error', e);
      Alert.alert('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨', e?.message ?? 'ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = async () => {
    try {
      if (timerRef.current) { clearInterval(timerRef.current); timerRef.current = null; }
      if (isRecording) {
        await recorder.stop();
        setAudioUri(recorder.uri ?? undefined);
      }
    } catch (e) {
      // no-op
    } finally {
      setIsRecording(false);
      setLevel(0);
    }
  };

  const onNext = async () => {
    const newHist = [...history, { q: question, a: audioUri ? `[audio] ${audioUri}` : '(no audio)' }];
    setHistory(newHist);
    setLoading(true);
    try {
      const res = await requestNextQuestion(settings, newHist, { maxQ: 5 });
      if (res.done) {
        navigation.replace('Summary', { sessionId: route.params?.sessionId ?? 'local' });
      } else if (res.question) {
        setQuestion(res.question);
        setIndex((i) => i + 1);
        setFollowups(0);
        setAudioUri(undefined);
        setRemain(90);
        setIsRecording(false);
      }
    } catch (e: any) {
      Alert.alert('ë‹¤ìŒ ì§ˆë¬¸ ì‹¤íŒ¨', e?.message ?? 'ì„œë²„ ì˜¤ë¥˜');
    } finally {
      setLoading(false);
    }
  };

  const progress = Math.min(1, (index - 1) / maxQ);

  return (
    <View style={styles.container}>
      {/* ìƒë‹¨ í—¤ë” */}
      <View style={styles.topBar}>
        <Text style={styles.badge}>Q {index}/{maxQ}</Text>
        <Text style={styles.badgeAlt}>íŒ”ë¡œì—… {followups}/2</Text>
      </View>
      <View style={styles.progress}><View style={[styles.progressFill, { width: `${progress * 100}%` }]} /></View>

      {/* ì§ˆë¬¸ ì¹´ë“œ */}
      <View style={styles.card}>
        <Text style={styles.q}>{question || (loading ? 'ì§ˆë¬¸ ìƒì„± ì¤‘â€¦' : 'ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì„¸ìš”')}</Text>
        <View style={styles.tagRow}>
          {['ì„±ëŠ¥', 'ë””ë²„ê¹…', 'ë©”ëª¨ë¦¬ ê´€ë¦¬'].map(t => (
            <View key={t} style={styles.tag}><Text style={styles.tagText}>{t}</Text></View>
          ))}
        </View>
      </View>

      {/* â–¼â–¼ ìƒˆ ë…¹ìŒ íŒ¨ë„ UI â–¼â–¼ */}
      <View style={[styles.card, { marginTop: 12, alignItems: 'center', paddingVertical: 16 }]}>
        <Text style={{ color: '#6b7280', marginBottom: 8 }}>{remain}s</Text>

        <Animated.View
          style={[
            styles.micOuter,
            isRecording && { borderColor: '#FACC15', shadowOpacity: 0.35 },
            {
              transform: [{
                scale: isRecording
                  ? pulse.interpolate({ inputRange: [0, 1], outputRange: [1, 1 + level * 0.25 + 0.05] })
                  : 1,
              }],
            },
          ]}
        >
          <Pressable
            onPress={handleMicPress}
            style={({ pressed }) => [styles.micInner, pressed && { opacity: 0.9 }]}
          >
            <MaterialCommunityIcons
              name={isRecording ? 'microphone' : 'microphone-outline'}
              size={36}
              color="#FACC15"
            />
          </Pressable>
        </Animated.View>

        <Waveform level={level} isRecording={isRecording} />

        <Text style={{ marginTop: 8, color: '#6b7280' }}>
          {isRecording ? 'ë…¹ìŒ ì¤‘â€¦' : (audioUri ? 'ì™„ë£Œ' : 'ëŒ€ê¸° ì¤‘')}
        </Text>
      </View>
      {/* â–²â–² ìƒˆ ë…¹ìŒ íŒ¨ë„ UI â–²â–² */}

      {/* í•˜ë‹¨ ë³´ì¡° ë²„íŠ¼ + ë‹¤ìŒ */}
      <View style={{ flexDirection: 'row', gap: 12, marginTop: 12 }}>
        <SmallBtn label="ë‹¤ì‹œ ì§ˆë¬¸" onPress={() => { /* ì„œë²„ ì¬ìƒì„± ë¡œì§ ê°€ëŠ¥ */ }} />
        <SmallBtn label="ìŠ¤í‚µ (1íšŒ)" onPress={() => onNext()} />
      </View>

      <Pressable
        onPress={onNext}
        disabled={loading || (!audioUri && !isRecording)}
        style={({ pressed }) => [styles.cta, pressed && { opacity: 0.85 }, (loading || (!audioUri && !isRecording)) && { opacity: 0.5 }]}
      >
        {loading ? <ActivityIndicator /> : <Text style={styles.ctaText}>ë‹¤ìŒ ì§ˆë¬¸</Text>}
      </Pressable>
    </View>
  );
};

/** ê°„ë‹¨í•œ íŒŒí˜•: ë ˆë²¨(0~1)ì— ë¹„ë¡€í•´ ë§‰ëŒ€ ë†’ì´ ë³€í™” */
function Waveform({ level, isRecording }: { level: number; isRecording: boolean }) {
  const bars = 18;
  const arr = Array.from({ length: bars });
  return (
    <View style={{ flexDirection: 'row', alignItems: 'center', height: 48, marginTop: 14 }}>
      {arr.map((_, i) => {
        const phase = (i / bars) * Math.PI;
        const h = 6 + Math.pow(Math.sin(phase), 2) * (14 + 60 * level);
        return (
          <View
            key={i}
            style={{
              width: 4,
              height: h,
              borderRadius: 2,
              marginHorizontal: 2,
              backgroundColor: isRecording ? '#FDE047' : '#D1D5DB',
            }}
          />
        );
      })}
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, paddingHorizontal: 16, paddingTop: 12, backgroundColor: '#fff' },
  topBar: { flexDirection: 'row', justifyContent: 'space-between', alignItems: 'center', marginBottom: 8 },
  badge: { fontSize: 12, color: '#1f2937' },
  badgeAlt: { fontSize: 12, color: '#6b7280' },
  progress: { height: 6, backgroundColor: '#E5E7EB', borderRadius: 999, overflow: 'hidden' },
  progressFill: { height: '100%', backgroundColor: '#9ca3af' },
  card: { backgroundColor: '#F3F4F6', borderRadius: 12, padding: 12, borderWidth: 1, borderColor: '#E5E7EB', marginTop: 12 },
  q: { fontSize: 16, fontWeight: '600', color: '#111827' },
  tagRow: { flexDirection: 'row', marginTop: 8 },
  tag: { backgroundColor: '#EEF2FF', borderRadius: 12, paddingHorizontal: 8, paddingVertical: 4, marginRight: 6 },
  tagText: { fontSize: 12, color: '#374151' },

  // ìƒˆ ë§ˆì´í¬ ë²„íŠ¼
  micOuter: {
    width: 120, height: 120, borderRadius: 60,
    borderWidth: 6, borderColor: '#E5E7EB',
    alignItems: 'center', justifyContent: 'center',
    backgroundColor: 'transparent',
    shadowColor: '#FACC15', shadowOffset: { width: 0, height: 0 }, shadowRadius: 16, shadowOpacity: 0,
  },
  micInner: {
    width: 108, height: 108, borderRadius: 54,
    alignItems: 'center', justifyContent: 'center',
    backgroundColor: '#0F172A',
  },

  smallBtn: { flex: 1, height: 44, borderRadius: 12, borderWidth: 1, borderColor: '#E5E7EB', alignItems: 'center', justifyContent: 'center', backgroundColor: '#fff' },
  smallBtnText: { color: '#111827', fontSize: 14 },
  cta: { height: 48, borderRadius: 12, backgroundColor: '#111827', alignItems: 'center', justifyContent: 'center', marginTop: 12 },
  ctaText: { color: '#fff', fontSize: 16, fontWeight: '600' },
});

export default Question;
